{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Structure\n",
    "\n",
    "**Nombre:** David L. Mejía<br>\n",
    "**Fecha:** 30/09/2025<br>\n",
    "**Git:** https://github.com/mcdavidleonardo/MachineLearning2/blob/master/DataStructure.ipynb<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Structure (Pandas)\n",
    "- Librería de Python que permite trabajar con conjuntos de datos en memoria\n",
    "- Nombre del paquete se deriva de panel data\n",
    "- Estructuras de datos y herramientas estadísticas para uso en aplicaciones de finanzas cuantitativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importar librería\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframes\n",
    "\n",
    "- Lista bidimensional con índice para identificación única\n",
    "- Permite manejar tipos de datos mixtos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Empleado': ['Ana', 'Luis', 'Clara'], 'Marca': ['HP', 'Lenovo', 'Asus'], 'Ventas (USD)': [12500, 8900, 15100], '¿Cumplió Meta?': [True, False, True]}\n",
      "<class 'dict'>\n",
      "  Empleado   Marca  Ventas (USD)  ¿Cumplió Meta?\n",
      "0      Ana      HP         12500            True\n",
      "1     Luis  Lenovo          8900           False\n",
      "2    Clara    Asus         15100            True\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Se crea un diccionario con datos para poder crear el dataframe\n",
    "datos = {\n",
    "    'Empleado': ['Ana', 'Luis', 'Clara'],\n",
    "    'Marca': ['HP', 'Lenovo', 'Asus'],\n",
    "    'Ventas (USD)': [12500, 8900, 15100],\n",
    "    '¿Cumplió Meta?': [True, False, True]\n",
    "}\n",
    "print(datos)\n",
    "print(type(datos))\n",
    "\n",
    "# Se crea el dataframe\n",
    "df_ventas = pd.DataFrame(datos)\n",
    "print(df_ventas)\n",
    "print(type(df_ventas))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID_Producto    Categoría  Precio  Stock\n",
      "0          101  Electrónica   49.99    150\n",
      "1          102        Hogar   12.50    300\n",
      "2          103  Electrónica  199.99     50\n",
      "\n",
      "Tipos de datos (dtypes):\n",
      "ID_Producto      int64\n",
      "Categoría       object\n",
      "Precio         float64\n",
      "Stock            int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Lectura desde un archivo excel\n",
    "# Se debe instalar openpyxl (pip install pandas openpyxl)\n",
    "nombre_archivo = 'reporte_venta.xlsx'\n",
    "\n",
    "df_ventas2 = pd.read_excel(nombre_archivo)\n",
    "print(df_ventas2)\n",
    "\n",
    "# Se puede ver los tipos de datos de cada columna\n",
    "print(\"\\nTipos de datos (dtypes):\")\n",
    "print(df_ventas2.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Notas\n",
      "1     15\n",
      "2     12\n",
      "3     18\n",
      "4     11\n",
      "   Notas\n",
      "4   11.0\n",
      "2   12.0\n",
      "5    NaN\n",
      "1   15.0\n",
      "3   18.0\n"
     ]
    }
   ],
   "source": [
    "# reindex\n",
    "# Se utiliza para cambiar, añadir, eliminar o reordenar las etiquetas de filas (el índice)\n",
    "# o las etiquetas de columnas, y rellena los valores faltantes con un valor por defecto,\n",
    "# que es NaN (Not a Number).\n",
    "\n",
    "# Dataframe con datos de 4 días\n",
    "data = {'Notas': [15, 12, 18, 11]}\n",
    "df_original = pd.DataFrame(data, index=[1, 2, 3, 4])\n",
    "print(df_original)\n",
    "\n",
    "# Se define el nuevo índice (se crea uno adicional 5)\n",
    "nuevo_orden = [4, 2, 5, 1, 3]\n",
    "\n",
    "# Se aplica reindex\n",
    "df_reindexado = df_original.reindex(nuevo_orden)\n",
    "\n",
    "print(df_reindexado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Notas\n",
      "4   11.0\n",
      "2   12.0\n",
      "5    0.0\n",
      "1   15.0\n",
      "3   18.0\n"
     ]
    }
   ],
   "source": [
    "# Para manejar los valores NaN se puede usar el método fillna()\n",
    "# Rellenar todos los NaN numéricos con 0\n",
    "df_cero = df_reindexado.fillna(0)\n",
    "print(df_cero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Región Producto  Venta (USD)\n",
      "0  Norte        A          100\n",
      "1    Sur        B           50\n",
      "2  Norte        A          150\n",
      "3   Este        C          200\n",
      "4    Sur        B           75\n",
      "5  Norte        C          125\n",
      "\n",
      "--- Resultado de Group By (Venta Promedio por Región) ---\n",
      "Región\n",
      "Este     200.0\n",
      "Norte    125.0\n",
      "Sur       62.5\n",
      "Name: Venta (USD), dtype: float64\n",
      "\n",
      "--- Agrupación por Región Y Producto (Suma de Venta) ---\n",
      "Región  Producto\n",
      "Este    C           200\n",
      "Norte   A           250\n",
      "        C           125\n",
      "Sur     B           125\n",
      "Name: Venta (USD), dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Uso de group by\n",
    "# Permite dividir el dataframe en grupos basados en los valores de una o más columnas,\n",
    "# y aplicar una función a cada grupo (como la suma, la media, o el conteo) y combinar los resultados.\n",
    "\n",
    "# Datos de ventas con dos columnas categóricas (Región, Producto) y una numérica (Venta)\n",
    "datos = {\n",
    "    'Región': ['Norte', 'Sur', 'Norte', 'Este', 'Sur', 'Norte'],\n",
    "    'Producto': ['A', 'B', 'A', 'C', 'B', 'C'],\n",
    "    'Venta (USD)': [100, 50, 150, 200, 75, 125]\n",
    "}\n",
    "df_ventas = pd.DataFrame(datos)\n",
    "\n",
    "print(df_ventas)\n",
    "\n",
    "# Se agrupa por región\n",
    "df_promedio_region = df_ventas.groupby('Región')['Venta (USD)'].mean()\n",
    "\n",
    "print(\"\\n--- Resultado de Group By (Venta Promedio por Región) ---\")\n",
    "print(df_promedio_region)\n",
    "\n",
    "# Se agrupa por región y producto\n",
    "df_multi_grupo = df_ventas.groupby(['Región', 'Producto'])['Venta (USD)'].sum()\n",
    "\n",
    "print(\"\\n--- Agrupación por Región Y Producto (Suma de Venta) ---\")\n",
    "print(df_multi_grupo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos Estadísticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Horas_Estudio  Calificacion_Final\n",
      "0              2                  60\n",
      "1              4                  75\n",
      "2              3                  70\n",
      "3              5                  85\n",
      "4              1                  55\n",
      "5              6                  90\n",
      "6              7                  95\n",
      "7              3                  65\n",
      "8              5                  80\n"
     ]
    }
   ],
   "source": [
    "# Mínimo Cuadrado Ordinario (OLS)\n",
    "# Método para Regresión Lineal para encontrar la línea que mejor se ajusta a un conjunto de puntos\n",
    "# minimizando la suma de los errores cuadrados.\n",
    "# Se requiere instalar statsmodels (pip install statsmodels)\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Se crea el dataframe\n",
    "datos = {\n",
    "    'Horas_Estudio': [2, 4, 3, 5, 1, 6, 7, 3, 5],\n",
    "    'Calificacion_Final': [60, 75, 70, 85, 55, 90, 95, 65, 80]\n",
    "}\n",
    "df = pd.DataFrame(datos)\n",
    "\n",
    "# Se define la fórmula del modelo OLS\n",
    "# Predecir 'Calificacion_Final' por 'Horas_Estudio' ejecutadas.\n",
    "# La fórmula es: Variable_Dependiente ~ Variable_Independiente\n",
    "modelo_formula = 'Calificacion_Final ~ Horas_Estudio'\n",
    "\n",
    "# El método .fit() calcula los coeficientes OLS\n",
    "modelo_ols = smf.ols(formula=modelo_formula, data=df).fit()\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumen del Modelo OLS\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:     Calificacion_Final   R-squared:                       0.980\n",
      "Model:                            OLS   Adj. R-squared:                  0.977\n",
      "Method:                 Least Squares   F-statistic:                     343.0\n",
      "Date:                Tue, 30 Sep 2025   Prob (F-statistic):           3.32e-07\n",
      "Time:                        21:32:50   Log-Likelihood:                -18.188\n",
      "No. Observations:                   9   AIC:                             40.38\n",
      "Df Residuals:                       7   BIC:                             40.77\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept        47.0000      1.662     28.281      0.000      43.070      50.930\n",
      "Horas_Estudio     7.0000      0.378     18.520      0.000       6.106       7.894\n",
      "==============================================================================\n",
      "Omnibus:                        0.243   Durbin-Watson:                   0.633\n",
      "Prob(Omnibus):                  0.885   Jarque-Bera (JB):                0.390\n",
      "Skew:                           0.000   Prob(JB):                        0.823\n",
      "Kurtosis:                       1.980   Cond. No.                         11.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nResumen del Modelo OLS\")\n",
    "print(modelo_ols.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En base a los datos de la tabla se puede deducir la fórmula\n",
    "# Intercept --> 50.930\n",
    "# Horas_Estudio --> 7.894\n",
    "# coef --> 0.975 (Valor de ajuste)\n",
    "# calificacion final = 50.930 + (7.894 * Horas_Estudio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Proyecto Fecha_Inicio\n",
      "0    Alpha   2023-01-15\n",
      "1     Beta   2024-02-29\n",
      "2    Gamma   2023-12-31\n",
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Uso de DateOffset\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "\n",
    "# Dataframe con fechas de inicio de proyectos\n",
    "data = {\n",
    "    'Proyecto': ['Alpha', 'Beta', 'Gamma'],\n",
    "    # Se convierte la lista de strings a tipo datetime\n",
    "    'Fecha_Inicio': pd.to_datetime(['2023-01-15', '2024-02-29', '2023-12-31']) \n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n",
    "print(df['Fecha_Inicio'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Proyecto Fecha_Inicio Fecha_Final_Esperada\n",
      "0    Alpha   2023-01-15           2025-01-15\n",
      "1     Beta   2024-02-29           2026-02-28\n",
      "2    Gamma   2023-12-31           2025-12-31\n"
     ]
    }
   ],
   "source": [
    "# Se va a sumar 2 años a las fechas originales\n",
    "dos_anios = DateOffset(years=2)\n",
    "\n",
    "# Pandas permite sumar el objeto DateOffset directamente\n",
    "df['Fecha_Final_Esperada'] = df['Fecha_Inicio'] + dos_anios\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-01    100\n",
      "2025-01-15    150\n",
      "2025-02-01    120\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Uso de asfreq\n",
    "# Se utiliza para remuestrear una serie temporal a una nueva frecuencia o para cambiar\n",
    "# la frecuencia de una serie ya existente\n",
    "\n",
    "# Índice de fechas irregular (días 1 y 15 de enero)\n",
    "indice_irregular = pd.to_datetime(['2025-01-01', '2025-01-15', '2025-02-01'])\n",
    "ventas = pd.Series([100, 150, 120], index=indice_irregular)\n",
    "\n",
    "print(ventas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-01    100.0\n",
      "2025-01-02      NaN\n",
      "2025-01-03      NaN\n",
      "2025-01-04      NaN\n",
      "2025-01-05      NaN\n",
      "2025-01-06      NaN\n",
      "2025-01-07      NaN\n",
      "2025-01-08      NaN\n",
      "Freq: D, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Se aplica asfreq a frecuencia diaria ('D')\n",
    "ventas_diarias_nan = ventas.asfreq('D')\n",
    "\n",
    "print(ventas_diarias_nan.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-01    100\n",
      "2025-01-02    100\n",
      "2025-01-03    100\n",
      "2025-01-04    100\n",
      "2025-01-05    100\n",
      "2025-01-06    100\n",
      "2025-01-07    100\n",
      "2025-01-08    100\n",
      "Freq: D, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Se aplica asfreq() y se rellena con el último valor conocido (ffill)\n",
    "ventas_diarias_ffill = ventas.asfreq('D', method='ffill')\n",
    "\n",
    "print(ventas_diarias_ffill.head(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "- Pandas es un componente que facilita el análisis de datos estadísticos en Python, es robusto y fácil de entender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
